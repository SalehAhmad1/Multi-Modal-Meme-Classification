{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eceafd2a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eceafd2a",
    "outputId": "b1e6a8bb-4e78-4c40-e3e4-63aed349315d",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from skimage import filters\n",
    "from skimage import feature\n",
    "from skimage.filters import prewitt_h,prewitt_v\n",
    "from skimage.io import imread, imshow\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "# %pip install -U git+https://github.com/szagoruyko/pytorchviz.git@master\n",
    "# from torchviz import make_dot, make_dot_from_trace\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "import time\n",
    "import torch\n",
    "import imghdr\n",
    "import nltk\n",
    "# nltk.download('punkt')\n",
    "from nltk.tokenize import word_tokenize\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from itertools import chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "defbdc64",
   "metadata": {
    "id": "defbdc64"
   },
   "outputs": [],
   "source": [
    "parent=r'C:\\Users\\SalehAhmad\\Downloads'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "690dadd6",
   "metadata": {
    "id": "690dadd6"
   },
   "outputs": [],
   "source": [
    "featured_path=parent+'\\Copy\\FeaturedImages'\n",
    "# featured_path ='/content/drive/MyDrive/FeaturedImages'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "MufeSQic1Zzp",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MufeSQic1Zzp",
    "outputId": "071818be-e7a5-47f7-a819-5cfdf05c631d"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7b75878",
   "metadata": {
    "id": "e7b75878"
   },
   "source": [
    "# Glove 6B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "567a8252",
   "metadata": {
    "id": "567a8252"
   },
   "outputs": [],
   "source": [
    "# glove_path=\"/content/drive/MyDrive/Glove_6B\"\n",
    "glove_path=parent+\"\\Glove6B\"\n",
    "os.chdir(glove_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53105fc2",
   "metadata": {
    "id": "53105fc2"
   },
   "outputs": [],
   "source": [
    "def glove_model(glove_path):\n",
    "    glove_dict = {}\n",
    "    with open(glove_path+'/'+'glove.6B.300d.txt','r',encoding=\"utf8\") as f:\n",
    "        for line in f:\n",
    "            string = line.split()\n",
    "            word = string[0]\n",
    "            feature = np.array(string[1:], dtype=np.float64)\n",
    "            glove_dict[word] = feature\n",
    "    return glove_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f63e6c9c",
   "metadata": {
    "id": "f63e6c9c"
   },
   "outputs": [],
   "source": [
    "glove=glove_model(glove_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89fb6e5f",
   "metadata": {
    "id": "89fb6e5f"
   },
   "source": [
    "# All Images DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff16101f",
   "metadata": {
    "id": "ff16101f"
   },
   "outputs": [],
   "source": [
    "os.chdir(r\"C:\\Users\\SalehAhmad\\Downloads\\Copy\")\n",
    "df=pd.read_csv(\"ALL.csv\")\n",
    "df.loc[df['overall_sentiment'] =='0' , 'overall_sentiment'] = 1\n",
    "df.loc[df['overall_sentiment'] =='1' , 'overall_sentiment'] = 2\n",
    "df.loc[df['overall_sentiment'] =='2' , 'overall_sentiment'] = 0\n",
    "\n",
    "df.loc[df['humour'] =='funny' , 'humour'] = 1\n",
    "df.loc[df['humour'] =='very_funny' , 'humour'] = 1\n",
    "df.loc[df['humour'] =='hilarious' , 'humour'] = 1\n",
    "df.loc[df['humour'] =='not_funny' , 'humour'] = 0\n",
    "\n",
    "\n",
    "df.loc[df['sarcasm'] =='general' , 'sarcasm'] = 1\n",
    "df.loc[df['sarcasm'] =='twisted_meaning' , 'sarcasm'] = 1\n",
    "df.loc[df['sarcasm'] =='very_twisted' , 'sarcasm'] = 1\n",
    "df.loc[df['sarcasm'] =='not_sarcastic' , 'sarcasm'] = 0\n",
    "\n",
    "\n",
    "df.loc[df['offensive'] =='offensive' , 'offensive'] = 1\n",
    "df.loc[df['offensive'] =='slight' , 'offensive'] = 1\n",
    "df.loc[df['offensive'] =='hateful_offensive' , 'offensive'] = 1\n",
    "df.loc[df['offensive'] =='very_offensive' , 'offensive'] = 1\n",
    "df.loc[df['offensive'] =='not_offensive' , 'offensive'] = 0\n",
    "\n",
    "df.loc[df['motivational'] =='not_motivational' , 'motivational'] = 0\n",
    "df.loc[df['motivational'] =='motivational' , 'motivational'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "839d74f8",
   "metadata": {
    "id": "839d74f8"
   },
   "outputs": [],
   "source": [
    "df.to_csv('ALLnew.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbb6aa78",
   "metadata": {
    "id": "cbb6aa78"
   },
   "outputs": [],
   "source": [
    "# os.chdir('/content/drive/MyDrive/Project_AI')\n",
    "os.chdir(r'C:\\Users\\SalehAhmad\\Downloads\\Copy')\n",
    "df=pd.read_csv(\"ALLnew.csv\")\n",
    "df=df.drop(labels=\"Unnamed: 0.1\",axis=1)\n",
    "df=df.drop(labels=\"Unnamed: 0\",axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f2c7205",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 745
    },
    "id": "7f2c7205",
    "outputId": "2e773bd2-2e2e-4412-fd2b-4713d7811206"
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45c3e085",
   "metadata": {
    "id": "45c3e085"
   },
   "source": [
    "# Features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "025686e2",
   "metadata": {
    "id": "025686e2"
   },
   "outputs": [],
   "source": [
    "def image_features(img):\n",
    "    os.chdir(featured_path)\n",
    "    image1 =imread(img,as_gray=True)\n",
    "    feature =np.array(image1,dtype='float32')\n",
    "    return feature\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cefb866d",
   "metadata": {
    "id": "cefb866d"
   },
   "outputs": [],
   "source": [
    "def text_features(img):\n",
    "    os.chdir(featured_path)\n",
    "    feature=[]\n",
    "    line=df[df['image_name'] ==img]['text_corrected'].iloc[0]\n",
    "    text=line\n",
    "    text=text.lower()\n",
    "    words=word_tokenize(text)\n",
    "    for j in words:\n",
    "        try:\n",
    "            feature.append(glove[j])\n",
    "        except:\n",
    "            pass\n",
    "    feature=np.array(feature).flatten()\n",
    "    maxi=62100\n",
    "    feature=np.pad(feature,(0,maxi-len(feature)))\n",
    "    return feature"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2310a18d",
   "metadata": {
    "id": "2310a18d"
   },
   "source": [
    "# Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "780363c1",
   "metadata": {
    "id": "780363c1",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class Data(Dataset):\n",
    "    def __init__(self,df,train,test):\n",
    "        self.all_images = (np.array(df['image_name'])).tolist()\n",
    "        self.labels = (np.array(df[['humour','sarcasm','offensive','motivational']])).tolist()\n",
    "        self.train_images = int((len(df)*0.8))\n",
    "        self.valid_ratio = len(df) - self.train_images\n",
    "       \n",
    "        \n",
    "        if train == True:\n",
    "            self.images = self.all_images[:self.train_images]\n",
    "            self.label = self.labels[:self.train_images]\n",
    "\n",
    "            self.transform = transforms.Compose([\n",
    "                transforms.ToPILImage(),\n",
    "                transforms.Resize((270, 275)),\n",
    "                transforms.RandomHorizontalFlip(p=0.5),\n",
    "                transforms.RandomRotation(degrees=90),\n",
    "                transforms.ToTensor(),\n",
    "            ])\n",
    "            \n",
    "        elif test==True:\n",
    "            self.images = list(self.all_images[-self.valid_ratio:])\n",
    "            self.label = list(self.labels[-self.valid_ratio:])\n",
    "            \n",
    "            self.transform = transforms.Compose([\n",
    "                transforms.ToPILImage(),\n",
    "                transforms.Resize((270, 275)),\n",
    "                transforms.ToTensor(),\n",
    "            ])\n",
    "           \n",
    "            \n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "    \n",
    "    def __getitem__(self, position):\n",
    "        tf= text_features(self.images[position])\n",
    "        img = image_features(self.images[position])\n",
    "        img = self.transform(img)\n",
    "        img = img.flatten()\n",
    "        outputlabel = self.label[position]\n",
    "       \n",
    "        outputlabel= torch.tensor(outputlabel, dtype=torch.float32)\n",
    "        img= torch.tensor(img, dtype=torch.float32)\n",
    "        tf=  torch.tensor(tf, dtype=torch.float32)\n",
    "        dict1= {\"Image\":img,\"Text\":tf,\"OutputLabel\":outputlabel}\n",
    "\n",
    "        return dict1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5a60db4",
   "metadata": {
    "id": "d5a60db4"
   },
   "source": [
    "# Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a90d4f7",
   "metadata": {
    "id": "1a90d4f7"
   },
   "outputs": [],
   "source": [
    "class Multi_Model_NN(nn.Module):\n",
    "    def __init__(self,textinput,inputneurons,textH1,textH2,comH1,ImageH1,ImageH2,all4,ImageH3,textH3,ImageH4,comH2,comH3,sh1,sh2,Hh1,Hh2,mh1,mh2,oh1,oh2,outall):\n",
    "        super(Multi_Model_NN, self).__init__()\n",
    "        \n",
    "        self.text = nn.Sequential(\n",
    "            nn.Linear(textinput, textH1),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(textH1, textH2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(textH2, textH3)\n",
    "       )\n",
    "        self.image = nn.Sequential(\n",
    "            nn.Linear(inputneurons,ImageH1),\n",
    "            nn.Sigmoid(),\n",
    "            nn.Linear(ImageH1, ImageH2),\n",
    "            nn.Sigmoid(),\n",
    "            nn.Linear(ImageH2, ImageH3),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(ImageH3, ImageH4)\n",
    "        )\n",
    "        \n",
    "        self.combination_of_models = nn.Sequential(\n",
    "            nn.Linear(textH3+ImageH4,comH1),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(comH1,comH2),\n",
    "            nn.Sigmoid(),\n",
    "            nn.Linear(comH2,comH3),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(comH3,all4)\n",
    "        )\n",
    "        \n",
    "        self.sarcasm = nn.Sequential(\n",
    "            nn.Linear(all4, sh1),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(sh1, sh2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(sh2, outall),\n",
    "        )\n",
    "        \n",
    "        self.humour = nn.Sequential(\n",
    "            nn.Linear(all4, Hh1),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(Hh1, Hh2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(Hh2, outall),\n",
    "        )\n",
    "\n",
    "        self.motivational = nn.Sequential(\n",
    "            nn.Linear(all4, mh1),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(mh1, mh2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(mh2, outall),\n",
    "        )\n",
    "\n",
    "        self.offensive = nn.Sequential(\n",
    "            nn.Linear(all4, oh1),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(oh1, oh2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(oh2, outall),\n",
    "        )\n",
    "\n",
    "    def forward(self, img, text):\n",
    "        img_output = self.image(img)\n",
    "        t_output = self.text(text)\n",
    "\n",
    "        dual = torch.cat([t_output,img_output],1)\n",
    "        x = self.combination_of_models(dual)\n",
    "        \n",
    "        o_out = self.offensive(x)\n",
    "        m_out = self.motivational(x)\n",
    "        h_out = self.humour(x)\n",
    "        s_out = self.sarcasm(x)\n",
    "        \n",
    "        return o_out,m_out,h_out,s_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e97339ed",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e97339ed",
    "outputId": "476b6d4e-a363-46a5-e021-eb6c6631eb00"
   },
   "outputs": [],
   "source": [
    "imginputneurons=74250\n",
    "imghidden1=1000\n",
    "imghidden2=800\n",
    "imghidden3=600\n",
    "imghidden4=400\n",
    "\n",
    "\n",
    "textinput=62100\n",
    "texthidden1=1000\n",
    "texthidden2=700\n",
    "texthidden3=400\n",
    "\n",
    "\n",
    "comh1=700\n",
    "comh2=650\n",
    "comh3=600\n",
    "\n",
    "all4 =500\n",
    "sh1 = 300\n",
    "sh2 = 200\n",
    "\n",
    "Hh1= 400\n",
    "Hh2= 200\n",
    "\n",
    "mh1= 400\n",
    "mh2= 200\n",
    "\n",
    "oh1= 400 \n",
    "oh2= 200\n",
    "outall=2\n",
    "\n",
    "neural_network=Multi_Model_NN(textinput,imginputneurons,texthidden1,texthidden2,comh1,imghidden1,imghidden2,all4,imghidden3,texthidden3,imghidden4,comh2,comh3,sh1,sh2,Hh1,Hh2,mh1,mh2,oh1,oh2,outall)   \n",
    "print(neural_network.parameters)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bee40ff",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 417
    },
    "id": "7bee40ff",
    "outputId": "1aeb4089-acea-4c3a-b54b-aa8d7168fd30",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "training_data = Data(df, train=True, test=False)\n",
    "loader = DataLoader(training_data, batch_size=60,shuffle=True)\n",
    "\n",
    "criterion=nn.CrossEntropyLoss()\n",
    "optimizer=torch.optim.SGD(neural_network.parameters(), lr=0.001)\n",
    "llist = []\n",
    "epoches=8\n",
    "\n",
    "for x in range(epoches):\n",
    "    print(\"Epoches: \",x+1)\n",
    "    for key,value in enumerate(loader):\n",
    "        y_pred = neural_network(value['Image'],value[\"Text\"])\n",
    "        loss = 0\n",
    "        \n",
    "        for i in range(0,len(y_pred)):\n",
    "            loss += criterion(y_pred[i],torch.transpose(value['OutputLabel'],1,0)[i].long()) \n",
    "        \n",
    "        llist.append(loss.item())\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()  \n",
    "        optimizer.step() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caa1a704",
   "metadata": {
    "id": "caa1a704"
   },
   "source": [
    "# Saving the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cd4ae23",
   "metadata": {
    "id": "3cd4ae23"
   },
   "outputs": [],
   "source": [
    "model_path=parent+\"\\model_4labels.pth\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68ae0c8b",
   "metadata": {
    "id": "68ae0c8b"
   },
   "outputs": [],
   "source": [
    "torch.save(neural_network.state_dict(), model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0012788d",
   "metadata": {
    "id": "0012788d"
   },
   "source": [
    "# Loading Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1f9630e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a1f9630e",
    "outputId": "b1cbd41f-fd96-4f5d-857f-7daa8423ba9c"
   },
   "outputs": [],
   "source": [
    "multimodel =Multi_Model_NN(textinput,imginputneurons,texthidden1,texthidden2,comh1,imghidden1,imghidden2,all4,imghidden3,texthidden3,imghidden4,comh2,comh3,sh1,sh2,Hh1,Hh2,mh1,mh2,oh1,oh2,outall)     \n",
    "multimodel.load_state_dict(torch.load(model_path, map_location='cpu'))\n",
    "multimodel.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b5ba5d8",
   "metadata": {
    "id": "PSJhxSOskuiN"
   },
   "source": [
    "# Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cVR0bXE1fG6j",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "cVR0bXE1fG6j",
    "outputId": "ad5625e5-d110-43bb-bd15-1b9f56ead1f9"
   },
   "outputs": [],
   "source": [
    "images=np.array(df[\"image_name\"])\n",
    "os.chdir(featured_path)\n",
    "\n",
    "temp = Image.open(images[0])\n",
    "temp= temp.convert('L')\n",
    "temp = temp.resize((270,275))\n",
    "\n",
    "feature =np.array(temp,dtype='float32' )\n",
    "feature=feature.flatten()\n",
    "feature=torch.tensor(feature,dtype=torch.float32)\n",
    "\n",
    "t_feature=text_features(images[0])\n",
    "t_feature= torch.tensor(t_feature,dtype=torch.float32)\n",
    "\n",
    "make_dot(neural_network(feature.unsqueeze(0),t_feature.unsqueeze(0)), params=dict(neural_network.named_parameters())).render(\"i20_2367_Model_Part2\",\"png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8be759a6",
   "metadata": {
    "id": "8be759a6"
   },
   "source": [
    "# Testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aea246de",
   "metadata": {
    "id": "aea246de",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "testing_data = Data(df, train=False, test=True)\n",
    "testloader = DataLoader(testing_data, batch_size=60,shuffle=True)\n",
    "\n",
    "llist = []\n",
    "predict=[]\n",
    "actual=[]\n",
    "\n",
    "for key,value in enumerate(testloader):\n",
    "    y_pred = multimodel(value['Image'],value[\"Text\"])\n",
    "    loss = 0\n",
    "    for i in range(0,len(y_pred)):\n",
    "        loss += criterion(y_pred[i],torch.transpose(value['OutputLabel'],1,0)[i].long()) \n",
    "        actual.append(torch.transpose(value['OutputLabel'],1,0)[i].tolist())\n",
    "    \n",
    "    llist.append(loss.item())\n",
    "    for i in range(0,len(y_pred)):\n",
    "        predict.append(torch.argmax(y_pred[i], dim=1).tolist())\n",
    "    \n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "548b898b",
   "metadata": {
    "id": "548b898b"
   },
   "outputs": [],
   "source": [
    "actual = list(chain.from_iterable(actual))\n",
    "predict = list(chain.from_iterable(predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b3531a4",
   "metadata": {
    "id": "8b3531a4"
   },
   "source": [
    "# Accuracy and F1Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb24bd43",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eb24bd43",
    "outputId": "7d22894f-6236-4355-b960-381d507eb03c"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score,accuracy_score\n",
    "print(\"F1Score: \",f1_score(actual,predict,average='macro')*100)\n",
    "print(\"Accuracy: \",accuracy_score(actual,predict)*100)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b463ba7f",
   "metadata": {
    "id": "9_ECZk7fbExF"
   },
   "source": [
    "# Seperate F1 Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b54e3bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_data = Data(df, train=False, test=True)\n",
    "testloader = DataLoader(testing_data, batch_size=60,shuffle=True)\n",
    "\n",
    "llist = []\n",
    "predicthumor=[]\n",
    "predictsarcasm=[]\n",
    "predictmotivational=[]\n",
    "predictoffensive=[]\n",
    "\n",
    "actualhumor=[]\n",
    "actualsarcasm=[]\n",
    "actualmotivational=[]\n",
    "actualoffensive=[]\n",
    "\n",
    "for key,value in enumerate(testloader):\n",
    "    y_pred = multimodel(value['Image'],value[\"Text\"])\n",
    "    loss = 0\n",
    "    for i in range(0,len(y_pred)):\n",
    "        loss += criterion(y_pred[i],torch.transpose(value['OutputLabel'],1,0)[i].long()) \n",
    "        if i==0:\n",
    "            actualoffensive.append(torch.transpose(value['OutputLabel'],1,0)[i].tolist())\n",
    "        if i==1:\n",
    "            actualmotivational.append(torch.transpose(value['OutputLabel'],1,0)[i].tolist())\n",
    "        if i==2:\n",
    "            actualhumor.append(torch.transpose(value['OutputLabel'],1,0)[i].tolist())\n",
    "        if i==3:\n",
    "            actualsarcasm.append(torch.transpose(value['OutputLabel'],1,0)[i].tolist())\n",
    "\n",
    "    \n",
    "    llist.append(loss.item())\n",
    "    for i in range(0,len(y_pred)):\n",
    "        if i==0:\n",
    "            predictoffensive.append(torch.argmax(y_pred[i], dim=1).tolist())\n",
    "        if i==1:\n",
    "            predictmotivational.append(torch.argmax(y_pred[i], dim=1).tolist())\n",
    "        if i==2:\n",
    "            predicthumor.append(torch.argmax(y_pred[i], dim=1).tolist())\n",
    "        if i==3:\n",
    "            predictsarcasm.append(torch.argmax(y_pred[i], dim=1).tolist())\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "906c16b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "actualoffensive = list(chain.from_iterable(actualoffensive))\n",
    "actualmotivational = list(chain.from_iterable(actualmotivational))\n",
    "actualhumor = list(chain.from_iterable(actualhumor))\n",
    "actualsarcasm = list(chain.from_iterable(actualsarcasm))\n",
    "\n",
    "predictoffensive = list(chain.from_iterable(predictoffensive))\n",
    "predictmotivational = list(chain.from_iterable(predictmotivational))\n",
    "predicthumor = list(chain.from_iterable(predicthumor))\n",
    "predictsarcasm = list(chain.from_iterable(predictsarcasm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52438040",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score,accuracy_score\n",
    "print(\"\\t\\t\\t\\t\\t\\t Offensive\")\n",
    "print(\"F1Score: \",f1_score(actualoffensive,predictoffensive,average='macro')*100)\n",
    "print(\"Accuracy: \",accuracy_score(actualoffensive,predictoffensive)*100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "792beef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\t\\t\\t\\t\\t\\t Motivational\")\n",
    "print(\"F1Score: \",f1_score(actualmotivational,predictmotivational,average='macro')*100)\n",
    "print(\"Accuracy: \",accuracy_score(actualmotivational,predictmotivational)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5464fee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\t\\t\\t\\t\\t\\t Humor\")\n",
    "print(\"F1Score: \",f1_score(actualhumor,predicthumor,average='macro')*100)\n",
    "print(\"Accuracy: \",accuracy_score(actualhumor,predicthumor)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dccf045",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\t\\t\\t\\t\\t\\t Sarcasm\")\n",
    "print(\"F1Score: \",f1_score(actualsarcasm,predictsarcasm,average='macro')*100)\n",
    "print(\"Accuracy: \",accuracy_score(actualsarcasm,predictsarcasm)*100)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "20i_2367_Project_Part2_Final.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
