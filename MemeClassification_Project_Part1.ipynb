{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eceafd2a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eceafd2a",
    "outputId": "5d350dd6-87d1-4a9a-9101-ba3146eedc91"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from skimage import filters\n",
    "from skimage import feature\n",
    "from skimage.filters import prewitt_h,prewitt_v\n",
    "from skimage.io import imread, imshow\n",
    "import torch\n",
    "import imghdr\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "%pip install -U git+https://github.com/szagoruyko/pytorchviz.git@master\n",
    "from torchviz import make_dot, make_dot_from_trace\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "defbdc64",
   "metadata": {
    "id": "defbdc64"
   },
   "outputs": [],
   "source": [
    "parent=r'C:\\Users\\SalehAhmad\\Downloads'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "MufeSQic1Zzp",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MufeSQic1Zzp",
    "outputId": "6c3498e8-2bd2-4e62-9762-619752fcf2e1"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2427a06",
   "metadata": {},
   "source": [
    "# Image Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7613c0dc",
   "metadata": {
    "id": "7613c0dc"
   },
   "outputs": [],
   "source": [
    "os.chdir(parent)\n",
    "os.rename('image_960.jpe','image_960.jpg')\n",
    "os.rename('image_1615.PNG','image_1615.png')\n",
    "os.rename('image_1795.JPG','image_1795.jpg')\n",
    "os.rename('image_1803.JPG','image_1803.jpg')\n",
    "os.rename('image_1804.JPG','image_1804.jpg')\n",
    "os.remove('image_5119.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "624268ee",
   "metadata": {
    "id": "624268ee",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def image_names():\n",
    "    image_names=[]\n",
    "    os.chdir(parent+'\\images')\n",
    "    for i in os.listdir():\n",
    "        image1=imread(i)\n",
    "        if image1.shape[0]<2250 and image1.shape[1]<2250:\n",
    "            image_names.append(i)\n",
    "    return image_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6794078f",
   "metadata": {
    "id": "6794078f"
   },
   "outputs": [],
   "source": [
    "image_name= image_names()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbcdd70c",
   "metadata": {
    "id": "fbcdd70c"
   },
   "outputs": [],
   "source": [
    "for i in os.listdir():\n",
    "    if i not in image_name:\n",
    "        os.remove(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49cb2655",
   "metadata": {
    "id": "49cb2655"
   },
   "outputs": [],
   "source": [
    "def resized_images(new_path):\n",
    "    for i in image_name:\n",
    "        os.chdir(parent+'\\images')\n",
    "        temp = Image.open(i)\n",
    "        temp= temp.convert('L')\n",
    "        temp = temp.resize((350,390))\n",
    "        os.chdir(new_path)\n",
    "        temp.save(i)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccf622f0",
   "metadata": {
    "id": "ccf622f0"
   },
   "outputs": [],
   "source": [
    "new_path=parent+\"\\Copy\\Resized\"\n",
    "resized_images(new_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "220f405b",
   "metadata": {
    "id": "220f405b"
   },
   "outputs": [],
   "source": [
    "def featured_images(featured_path):\n",
    "    for i in image_name:\n",
    "        os.chdir(new_path)\n",
    "        img = Image.open(i)\n",
    "        pre_hor = prewitt_h(img)\n",
    "        pre_ver = prewitt_v(img)\n",
    "        previt=pre_hor+pre_ver\n",
    "        os.chdir(featured_path)\n",
    "        plt.imsave(i,previt,cmap='gray')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d67cd84",
   "metadata": {
    "id": "6d67cd84"
   },
   "outputs": [],
   "source": [
    "featured_path=\"/content/drive/MyDrive/FeaturedImages\"\n",
    "featured_images(featured_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11adf0bf",
   "metadata": {
    "id": "11adf0bf"
   },
   "outputs": [],
   "source": [
    "label_path=r\"C:\\Users\\SalehAhmad\\Downloads\\archive\\memotion_dataset_7k\"\n",
    "os.chdir(label_path)\n",
    "df=pd.read_excel('labels.xlsx')\n",
    "df=df.drop(labels=\"Unnamed: 0\",axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a37b46b0",
   "metadata": {
    "id": "a37b46b0",
    "outputId": "f866ca73-9638-464c-9007-fd752747e290"
   },
   "outputs": [],
   "source": [
    "removed=[]\n",
    "images=list(np.array(df['image_name']))\n",
    "for i in images:\n",
    "    if i not in image_name:\n",
    "        removed.append(i)\n",
    "list1=[ 'image_960.jpe','image_1615.PNG','image_1795.JPG','image_1803.JPG','image_1804.JPG']\n",
    "for i in list1:\n",
    "    removed.remove(i)\n",
    "\n",
    "for i in removed:\n",
    "    df.drop(df.index[df['image_name'] == i],axis=0,inplace=True)\n",
    "\n",
    "df.loc[df['overall_sentiment'] =='very_positive' , 'overall_sentiment'] = 0\n",
    "df.loc[df['overall_sentiment'] =='positive' , 'overall_sentiment'] = 0\n",
    "df.loc[df['overall_sentiment'] =='negative' , 'overall_sentiment'] = 1\n",
    "df.loc[df['overall_sentiment'] =='very_negative' , 'overall_sentiment'] = 1\n",
    "df.loc[df['overall_sentiment'] =='neutral' , 'overall_sentiment'] = 2\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "666aafcf",
   "metadata": {
    "id": "666aafcf"
   },
   "source": [
    "# Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6d050ca",
   "metadata": {
    "id": "e6d050ca"
   },
   "outputs": [],
   "source": [
    "neutral_names=list(df[df['overall_sentiment']==2]['image_name'])\n",
    "x=(df['overall_sentiment']==1)\n",
    "negative_img=df[x]['image_name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11226ada",
   "metadata": {
    "id": "11226ada"
   },
   "outputs": [],
   "source": [
    "def Neutral_Images_DataAugmentatation(featured_path):\n",
    "    os.chdir(featured_path)\n",
    "    for i in neutral_names:\n",
    "        image=Image.open(i)\n",
    "        x=imghdr.what(i)\n",
    "        rotated = image.rotate(180)\n",
    "        i=i.replace('.png','').replace('.jpeg','').replace('.jpg','').replace('.bmp','').replace('.JPG','')\n",
    "        i +=\"_rotated\"\n",
    "        name=i+'.'+x\n",
    "        os.chdir(featured_path)\n",
    "        rotated.save(name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7b944ba",
   "metadata": {
    "id": "e7b944ba"
   },
   "outputs": [],
   "source": [
    "Neutral_Images_DataAugmentatation(featured_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfd18532",
   "metadata": {
    "id": "bfd18532"
   },
   "outputs": [],
   "source": [
    "def Negative_Images_FlipTB(featured_path):\n",
    "    os.chdir(featured_path)\n",
    "    for i in negative_img:\n",
    "        image=Image.open(i)\n",
    "        x=imghdr.what(i)\n",
    "        flip=image.transpose(Image.FLIP_TOP_BOTTOM)\n",
    "        i=i.replace('.png','').replace('.jpeg','').replace('.jpg','').replace('.bmp','').replace('.JPG','')\n",
    "        i +=\"_flipTB\"\n",
    "        name=i+'.'+x\n",
    "        flip.save(name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0513d0bb",
   "metadata": {
    "id": "0513d0bb"
   },
   "outputs": [],
   "source": [
    "def rotate(featured_path,degree):\n",
    "    os.chdir(featured_path)\n",
    "    for i in negative_img:\n",
    "        image=Image.open(i)\n",
    "        x=imghdr.what(i)\n",
    "        rotated = image.rotate(degree,expand=True)\n",
    "        i=i.replace('.png','').replace('.jpeg','').replace('.jpg','').replace('.bmp','').replace('.JPG','')\n",
    "        if degree==180:\n",
    "            i +=\"_rotated180\"\n",
    "        elif degree==90:\n",
    "            i +=\"_rotated90\"\n",
    "        else:\n",
    "            i +=\"_rotated270\"\n",
    "        name=i+'.'+x\n",
    "        os.chdir(featured_path)\n",
    "        rotated.save(name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "034cf137",
   "metadata": {
    "id": "034cf137"
   },
   "outputs": [],
   "source": [
    "def Negative_Images_Rotate(featured_path):\n",
    "    rotate(featured_path,180)\n",
    "    rotate(featured_path,90)\n",
    "    rotate(featured_path,270)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15676e06",
   "metadata": {
    "id": "15676e06"
   },
   "outputs": [],
   "source": [
    "def Negative_Images_FlipLR(featured_path):\n",
    "    os.chdir(featured_path)\n",
    "    for i in negative_img:\n",
    "        image=Image.open(i)\n",
    "        x=imghdr.what(i)\n",
    "        flip=image.transpose(Image.FLIP_LEFT_RIGHT)\n",
    "        i=i.replace('.png','').replace('.jpeg','').replace('.jpg','').replace('.bmp','').replace('.JPG','')\n",
    "        i +=\"_flipLR\"\n",
    "        name=i+'.'+x\n",
    "        flip.save(name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e036de3d",
   "metadata": {
    "id": "e036de3d"
   },
   "outputs": [],
   "source": [
    "def Negative_Images_Rotated180_FlipLR(featured_path):\n",
    "    os.chdir(featured_path)\n",
    "    for i in negative_img:\n",
    "        x=imghdr.what(i)\n",
    "        i=i.replace('.png','').replace('.jpeg','').replace('.jpg','').replace('.bmp','').replace('.JPG','')\n",
    "        i +=\"_rotated180\"\n",
    "        name=i+'.'+x\n",
    "        image=Image.open(name)\n",
    "        flip=image.transpose(Image.FLIP_LEFT_RIGHT)\n",
    "        i=i.replace('.png','').replace('.jpeg','').replace('.jpg','').replace('.bmp','').replace('.JPG','')\n",
    "        i +=\"FLR\"\n",
    "        name=i+'.'+x\n",
    "        flip.save(name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29dee09d",
   "metadata": {
    "id": "29dee09d"
   },
   "outputs": [],
   "source": [
    "def Negative_Images_DataAugmentatation(featured_path):\n",
    "    Negative_Images_FlipTB(featured_path)\n",
    "    Negative_Images_FlipLR(featured_path)\n",
    "    Negative_Images_Rotate(featured_path)\n",
    "    Negative_Images_Rotated180_FlipLR(featured_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65b4f0dc",
   "metadata": {
    "id": "65b4f0dc"
   },
   "outputs": [],
   "source": [
    "Negative_Images_DataAugmentatation(featured_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7b75878",
   "metadata": {
    "id": "4f313072"
   },
   "source": [
    "# Glove 6B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "567a8252",
   "metadata": {
    "id": "567a8252"
   },
   "outputs": [],
   "source": [
    "glove_path=\"/content/drive/MyDrive/Glove_6B\"\n",
    "os.chdir(glove_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75c87950",
   "metadata": {
    "id": "75c87950"
   },
   "outputs": [],
   "source": [
    "Missing_text = [\"CHALLENGE ACCEPTED! Friend: You can't honestly watch How I Met Your Mother again for like the 4th time.. Me:\"\n",
    "       ,\"I'M GONNA BUILD SOME FANCY WALLS EVEN THOUGHIHAVE MILLIONS OF EXTRA DOLLARS IN GONNA MAKE THE MEXICANS PAY FORIT\"\n",
    "       ,\"IF DONALD AND HILLARY ARE TOGETHER ON A BOAT IN THE MIDDLE OF THE OCEAN AND IT SINKS. WHO SURVIVES? AMERICA\"\n",
    "       ,\"Bruh why this tub of margarine look like Donald Trump?\"\n",
    "       ,\"2016 ELECTION TRUMPS HILIARY STILL'A BETTER LOVE STORY THAN TWILIGHT\"]\n",
    "x=df[df['text_corrected'].isna()]\n",
    "nan_image_names=list(x['image_name'])\n",
    "for i in range(0,len(nan_image_names)):\n",
    "    df.loc[df['image_name'] ==nan_image_names[i] , 'text_corrected'] = Missing_text[i]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53105fc2",
   "metadata": {
    "id": "53105fc2"
   },
   "outputs": [],
   "source": [
    "def glove_model(glove_path):\n",
    "    glove_dict = {}\n",
    "    with open(glove_path+'/'+'glove.6B.300d.txt','r',encoding=\"utf8\") as f:\n",
    "        for line in f:\n",
    "            string = line.split()\n",
    "            word = string[0]\n",
    "            feature = np.array(string[1:], dtype=np.float64)\n",
    "            glove_dict[word] = feature\n",
    "    return glove_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f63e6c9c",
   "metadata": {
    "id": "f63e6c9c"
   },
   "outputs": [],
   "source": [
    "glove=glove_model(glove_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89fb6e5f",
   "metadata": {},
   "source": [
    "# All Images DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "288a70f6",
   "metadata": {
    "id": "288a70f6"
   },
   "outputs": [],
   "source": [
    "def append_Neutralrotatedimgs():\n",
    "    temp=pd.DataFrame()\n",
    "    for i in range(0,len(neutral_names)):\n",
    "        temp=temp.append(df.loc[df['image_name'] == neutral_names[i]])\n",
    "\n",
    "    os.chdir(featured_path)\n",
    "    for j in neutral_names:\n",
    "        x=imghdr.what(j)\n",
    "        i=j\n",
    "        i=i.replace('.png','').replace('.jpeg','').replace('.jpg','').replace('.bmp','').replace('.JPG','')\n",
    "        i +=\"_rotated\"\n",
    "        name=i+'.'+x\n",
    "        temp['image_name'].replace({j:name},inplace=True)\n",
    "    return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3381205f",
   "metadata": {
    "id": "3381205f"
   },
   "outputs": [],
   "source": [
    "x=append_Neutralrotatedimgs()\n",
    "df=pd.concat([df,x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1927a07f",
   "metadata": {
    "id": "1927a07f"
   },
   "outputs": [],
   "source": [
    "temp=pd.DataFrame()\n",
    "temp1=pd.DataFrame()\n",
    "temp2=pd.DataFrame()\n",
    "temp3=pd.DataFrame()\n",
    "temp4=pd.DataFrame()\n",
    "temp5=pd.DataFrame()\n",
    "\n",
    "for i in negative_img:\n",
    "        temp=temp.append(df.loc[df['image_name'] == i])\n",
    "        temp1=temp1.append(df.loc[df['image_name'] == i])\n",
    "        temp2=temp2.append(df.loc[df['image_name'] == i])\n",
    "        temp3=temp3.append(df.loc[df['image_name'] == i])\n",
    "        temp4=temp4.append(df.loc[df['image_name'] == i])\n",
    "        temp5=temp5.append(df.loc[df['image_name'] == i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4097516d",
   "metadata": {
    "id": "4097516d"
   },
   "outputs": [],
   "source": [
    "def append_Negativeimgs(string,df1):\n",
    "    os.chdir(featured_path)\n",
    "    names=np.array(df1['image_name'])\n",
    "    for j in range(0,len(names)):\n",
    "        img=names[j]\n",
    "        x=imghdr.what(img)\n",
    "        i=img\n",
    "        i=i.replace('.png','').replace('.jpeg','').replace('.jpg','').replace('.bmp','').replace('.JPG','')\n",
    "        i +=\"_\"+string\n",
    "        name=i+'.'+x\n",
    "        df1['image_name'].replace({img:name},inplace=True)\n",
    "        \n",
    "    return df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "332e04d3",
   "metadata": {
    "id": "332e04d3"
   },
   "outputs": [],
   "source": [
    "df2=append_Negativeimgs(\"rotated90\",temp)\n",
    "df=pd.concat([df,df2])\n",
    "df2=append_Negativeimgs(\"rotated180\",temp1)\n",
    "df=pd.concat([df,df2])\n",
    "df2=append_Negativeimgs(\"rotated270\",temp2)\n",
    "df=pd.concat([df,df2])\n",
    "df2=append_Negativeimgs(\"flipLR\",temp3)\n",
    "df=pd.concat([df,df2])\n",
    "df2=append_Negativeimgs(\"flipTB\",temp4)\n",
    "df=pd.concat([df,df2])\n",
    "df2=append_Negativeimgs(\"rotated180FLR\",temp5)\n",
    "df=pd.concat([df,df2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4c1e84d",
   "metadata": {
    "id": "c4c1e84d",
    "outputId": "79652720-c183-4cd0-bcf3-abf66822241e"
   },
   "outputs": [],
   "source": [
    "index=np.arange(0,12953)\n",
    "df.set_index(index,inplace=True)\n",
    "df.loc[df['image_name'] =='image_960.jpe' , 'image_name'] = 'image_960.jpg'\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d762a733",
   "metadata": {
    "id": "d762a733"
   },
   "outputs": [],
   "source": [
    "df.to_csv(\"ALL.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45c3e085",
   "metadata": {
    "id": "45c3e085"
   },
   "source": [
    "# Features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "025686e2",
   "metadata": {
    "id": "025686e2"
   },
   "outputs": [],
   "source": [
    "def image_features(img):\n",
    "    image1 =imread(img,as_gray=True)\n",
    "    feature =np.array(image1).flatten()\n",
    "    label=df[df['image_name'] ==img]['overall_sentiment'].iloc[0]\n",
    "    return feature,label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cefb866d",
   "metadata": {
    "id": "cefb866d"
   },
   "outputs": [],
   "source": [
    "def text_features(img):\n",
    "    feature=[]\n",
    "    line=df[df['image_name'] ==img]['text_corrected'].iloc[0]\n",
    "    text=line\n",
    "    text=text.lower()\n",
    "    words=word_tokenize(text)\n",
    "    for j in words:\n",
    "        try:\n",
    "            feature.append(glove[j])\n",
    "        except:\n",
    "            pass\n",
    "    feature=np.array(feature).flatten()\n",
    "    maxi=62100\n",
    "    feature=np.pad(feature,(0,maxi-len(feature)))\n",
    "    return feature"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "114f0d74",
   "metadata": {},
   "source": [
    "# Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "780363c1",
   "metadata": {
    "id": "780363c1",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "os.chdir(\"/content/drive/MyDrive/Project_AI\")\n",
    "df=pd.read_csv('ALL.csv')\n",
    "df=df.drop(labels=\"Unnamed: 0\",axis=1)\n",
    "df.loc[df['image_name'] =='image_1795.JPG' , 'image_name'] = 'image_1795.jpg'\n",
    "df.loc[df['image_name'] =='image_1615.PNG' , 'image_name'] = 'image_1615.png'\n",
    "df.loc[df['image_name'] =='image_1803.JPG' , 'image_name'] = 'image_1803.jpg'\n",
    "df.loc[df['image_name'] =='image_1804.JPG' , 'image_name'] = 'image_1804.jpg'\n",
    "\n",
    "train_df=df\n",
    "train_df=train_df.drop(labels='overall_sentiment',axis=1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(train_df, df['overall_sentiment'], test_size=0.3, random_state=30,shuffle=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5a60db4",
   "metadata": {
    "id": "d5a60db4"
   },
   "source": [
    "# Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a90d4f7",
   "metadata": {
    "id": "1a90d4f7"
   },
   "outputs": [],
   "source": [
    "class Multi_Model_NN(nn.Module):\n",
    "    def __init__(self,textinput,inputneurons,textH1,textH2,comH1,ImageH1,ImageH2,output,ImageH3,textH3,ImageH4):\n",
    "        super(Multi_Model_NN, self).__init__()\n",
    "        \n",
    "        self.text = nn.Sequential(\n",
    "            nn.Linear(textinput, textH1),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(textH1, textH2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(textH2, textH3)\n",
    "       )\n",
    "        self.image = nn.Sequential(\n",
    "            nn.Linear(inputneurons,ImageH1),\n",
    "            nn.Sigmoid(),\n",
    "            nn.Linear(ImageH1, ImageH2),\n",
    "            nn.Sigmoid(),\n",
    "            nn.Linear(ImageH2, ImageH3),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(ImageH3, ImageH4)\n",
    "        )\n",
    "        \n",
    "        self.combination_of_models = nn.Sequential(\n",
    "            nn.Linear(textH3+ImageH4,comH1),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(comH1,output)\n",
    "        )\n",
    "\n",
    "    def forward(self,lines,img):\n",
    "        t_output = self.text(lines)\n",
    "        img_output = self.image(img)\n",
    "        dual = torch.cat((t_output,img_output))\n",
    "        x = self.combination_of_models(dual)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e97339ed",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e97339ed",
    "outputId": "7b3c5068-caeb-4b2b-e94a-9bd1bcbdb5b8"
   },
   "outputs": [],
   "source": [
    "imginputneurons=350*390\n",
    "imghidden1=1800\n",
    "imghidden2=1200\n",
    "imghidden3=700\n",
    "imghidden4=400\n",
    "\n",
    "\n",
    "textinput=62100\n",
    "texthidden1=1500\n",
    "texthidden2=800\n",
    "texthidden3=500\n",
    "\n",
    "comh1=500\n",
    "output=3\n",
    "\n",
    "neural_network=Multi_Model_NN(textinput,imginputneurons,texthidden1,texthidden2,comh1,imghidden1,imghidden2,output,imghidden3,texthidden3,imghidden4).cuda()   \n",
    "print(neural_network.parameters)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bee40ff",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7bee40ff",
    "outputId": "77591e52-de26-4a86-dc79-fe853e7c75a5",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "criterion=nn.CrossEntropyLoss()\n",
    "optimizer=torch.optim.SGD(neural_network.parameters(), lr=0.001)\n",
    "\n",
    "os.chdir(featured_path)\n",
    "images=np.array(X_train[\"image_name\"])\n",
    "llist = []\n",
    "epoches=6\n",
    "for x in range(epoches):\n",
    "    print(\"Epoches: \",x+1)\n",
    "    for i in range(0,len(images)):\n",
    "        feature,label= image_features(images[i])\n",
    "        t_feature=text_features(images[i])\n",
    "        t_feature=torch.tensor(t_feature)\n",
    "        featuret=torch.tensor(feature)\n",
    "        label=torch.tensor(label)\n",
    "        y_pred = neural_network(t_feature.cuda().float(),featuret.cuda().float())\n",
    "\n",
    "        loss = criterion(y_pred, label.cuda().long())\n",
    "        llist.append(loss.item())\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()  \n",
    "        optimizer.step() \n",
    "  \n",
    "       "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc7d5f25",
   "metadata": {
    "id": "dc7d5f25"
   },
   "source": [
    "# Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6833f69",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "a6833f69",
    "outputId": "93159ddc-3496-404e-e02b-4179e54f7c8f",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "images=np.array(X_train[\"image_name\"])\n",
    "os.chdir(featured_path)\n",
    "feature,label= image_features(images[0])\n",
    "feature=torch.tensor(feature)\n",
    "t_feature=text_features(images[0])\n",
    "t_feature= torch.tensor(t_feature)\n",
    "make_dot(neural_network(t_feature.cuda().float(),feature.cuda().float()), params=dict(neural_network.named_parameters()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caa1a704",
   "metadata": {
    "id": "caa1a704"
   },
   "source": [
    "# Saving the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cd4ae23",
   "metadata": {
    "id": "3cd4ae23"
   },
   "outputs": [],
   "source": [
    "model_path=\"/content/drive/MyDrive/Project_AI\"+\"/model2.pth\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68ae0c8b",
   "metadata": {
    "id": "68ae0c8b"
   },
   "outputs": [],
   "source": [
    "torch.save(neural_network.state_dict(), model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0012788d",
   "metadata": {
    "id": "0012788d"
   },
   "source": [
    "# Loading Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1f9630e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a1f9630e",
    "outputId": "b1cbd41f-fd96-4f5d-857f-7daa8423ba9c"
   },
   "outputs": [],
   "source": [
    "multimodel = Multi_Model_NN(textinput,imginputneurons,texthidden1,texthidden2,comh1,imghidden1,imghidden2,output,imghidden3,texthidden3,imghidden4).cuda()   \n",
    "multimodel.load_state_dict(torch.load(model_path))\n",
    "multimodel.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8be759a6",
   "metadata": {},
   "source": [
    "# Testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8VdbfaeK4bx2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 554
    },
    "id": "8VdbfaeK4bx2",
    "outputId": "42af7fcc-3209-433d-aed2-5505b66f510d"
   },
   "outputs": [],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aea246de",
   "metadata": {
    "id": "aea246de"
   },
   "outputs": [],
   "source": [
    "os.chdir(featured_path)\n",
    "images=np.array(X_test[\"image_name\"])\n",
    "list1=[]\n",
    "actual_label=[]\n",
    "\n",
    "for i in range(0,len(images)):\n",
    "    feature,label= image_features(images[i])\n",
    "    actual_label.append(label)\n",
    "    t_feature=text_features(images[i])\n",
    "    t_feature=torch.tensor(t_feature)\n",
    "    featuret=torch.tensor(feature)\n",
    "    label=torch.tensor(label)\n",
    "    y_pred = neural_network(t_feature.cuda().float(),featuret.cuda().float())\n",
    "    list1.append(torch.argmax(y_pred).cpu().detach().numpy())\n",
    "  \n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b3531a4",
   "metadata": {},
   "source": [
    "# Accuracy and F1Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb24bd43",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eb24bd43",
    "outputId": "52b0e383-b925-45f6-800d-93c75de19806"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score,accuracy_score\n",
    "print(\"F1Score: \",f1_score(y_test,list1,average='macro')*100)\n",
    "print(\"Accuracy: \",accuracy_score(y_test,list1)*100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c1c8e05",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "20i-2367_Project_FinalFinal.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
